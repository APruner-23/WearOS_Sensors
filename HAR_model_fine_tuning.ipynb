{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fine Tuning"
      ],
      "metadata": {
        "id": "nD45UVS78IiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBHu2PAvV107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76daae3-a4f1-48b2-f23b-fd52955af24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "!pip install torch torchvision torchaudio --quiet\n",
        "!pip install numpy pandas scipy scikit-learn matplotlib seaborn --quiet"
      ],
      "metadata": {
        "id": "nCEQIN59V921"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/capture24_dataset'"
      ],
      "metadata": {
        "id": "YCRu2IkFWEOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os, numpy as np, torch\n",
        "import torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "YtmtzeGZWSXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NPYDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path):\n",
        "        # Apri in memmap: non carica tutto in RAM, ma mappa sul disco\n",
        "        self.X = np.load(x_path, mmap_mode='r')   # shape: (N, 3, T)\n",
        "        self.Y_str = np.load(y_path, mmap_mode='r')  # array di stringhe\n",
        "\n",
        "        uniques = np.unique(self.Y_str)\n",
        "        self.class2idx = {c: i for i, c in enumerate(uniques)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Leggi un singolo sample\n",
        "        x = self.X[idx].astype(np.float32)# (3, T)\n",
        "        y_str = self.Y_str[idx]\n",
        "        y = self.class2idx[y_str]\n",
        "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "H57adekIsdZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Parametri ===\n",
        "x_path = f'{dataset_path}/X.npy'\n",
        "y_path = f'{dataset_path}/Y.npy'\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 32\n",
        "\n",
        "ds = NPYDataset(x_path, y_path)\n",
        "loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "epochs = 10\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "s3tQ7GFwWXoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Carica modello SSL (solo per estrarre la dimensione)\n",
        "repo = 'OxWearables/ssl-wearables'\n",
        "tmp_model = torch.hub.load(repo, 'harnet10', class_num=5, pretrained=True, trust_repo=True)\n",
        "tmp_model.eval().to(device)\n",
        "\n",
        "# Dummy input: batch=1, 3 canali, 300 time steps\n",
        "dummy = torch.randn(1, 3, 300, device=device)\n",
        "\n",
        "# Estraggo feature\n",
        "with torch.no_grad():\n",
        "    feat = tmp_model.feature_extractor(dummy)\n",
        "\n",
        "feat_dim = feat.shape[1]\n",
        "print(\"Embedding dimension:\", feat_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukj8TOXItwdt",
        "outputId": "67e5a603-064e-4e68-8f91-a4af4e2a2d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/OxWearables_ssl-wearables_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 Weights loaded\n",
            "Embedding dimension: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Modello ===\n",
        "repo = 'OxWearables/ssl-wearables'\n",
        "num_classes = len(ds.class2idx)\n",
        "model = torch.hub.load(repo, 'harnet10', class_num=num_classes, pretrained=True)\n",
        "for p in model.feature_extractor.parameters(): p.requires_grad = False\n",
        "model.classifier = nn.Linear(feat_dim, num_classes)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "1hhRtsg8Y6E0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc0cea1-dd70-4cae-c1c4-24052acf50cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/OxWearables_ssl-wearables_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 Weights loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resnet(\n",
              "  (feature_extractor): Sequential(\n",
              "    (layer1): Sequential(\n",
              "      (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer5): Sequential(\n",
              "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Downsample()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.classifier.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "PUQ5uu_9Y9mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = correct = total = 0\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.permute(0, 2, 1)\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch}: Loss={total_loss/total:.4f}, Acc={correct/total:.4f}\")"
      ],
      "metadata": {
        "id": "c4lbkcsMY_di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48400597-4e23-46ca-f825-75d7ad52588e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss=0.5320, Acc=0.8023\n",
            "Epoch 2: Loss=0.5184, Acc=0.8074\n",
            "Epoch 3: Loss=0.5163, Acc=0.8084\n",
            "Epoch 4: Loss=0.5146, Acc=0.8089\n",
            "Epoch 5: Loss=0.5142, Acc=0.8092\n",
            "Epoch 6: Loss=0.5136, Acc=0.8092\n",
            "Epoch 7: Loss=0.5128, Acc=0.8097\n",
            "Epoch 8: Loss=0.5130, Acc=0.8102\n",
            "Epoch 9: Loss=0.5129, Acc=0.8093\n",
            "Epoch 10: Loss=0.5120, Acc=0.8099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Salva i pesi su Drive\n",
        "out_path = f'/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/finetuned_harnet10.pth'\n",
        "torch.save(model.state_dict(), out_path)\n",
        "print(\"Modello salvato in\", out_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2L-OebN6bL1",
        "outputId": "3490d2ef-bf88-4a6f-9146-1e6aedb862fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modello salvato in /content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/finetuned_harnet10.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of our data"
      ],
      "metadata": {
        "id": "dRFZx0lv8FzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0AnDcI_YUp",
        "outputId": "be1615c7-f791-4e30-87b9-174c2eaa2879"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_path = '/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/health_data.db'"
      ],
      "metadata": {
        "id": "quu1KSCI8AZf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_str = np.load('/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/capture24_dataset/Y.npy')  # update the path accordingly\n",
        "\n",
        "# Get unique class names and build mapping\n",
        "unique_classes = np.unique(Y_str)\n",
        "class2idx = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "idx2class = {idx: cls for cls, idx in class2idx.items()}\n",
        "\n",
        "print(\"idx2class:\", idx2class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZIqQBa0B94F",
        "outputId": "0b105eb2-c580-4bb5-f629-c9283112e938"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx2class: {0: np.str_('light'), 1: np.str_('moderate-vigorous'), 2: np.str_('sedentary'), 3: np.str_('sleep')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "u3NhER0v8W_L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_acc(db_path):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\n",
        "        \"SELECT x_value, y_value, z_value, timestamp FROM accelerometer ORDER BY timestamp\",\n",
        "        conn\n",
        "    )\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def resample_30hz(data, timestamps):\n",
        "    ts = pd.to_datetime(timestamps)\n",
        "    diffs = np.diff(ts.values).astype('timedelta64[ms]').astype(float)\n",
        "    rate = 1000. / diffs.mean()\n",
        "    if abs(rate - 30) < 1: return data\n",
        "    factor = 30. / rate\n",
        "    N = int(len(data) * factor)\n",
        "    out = np.zeros((N,3))\n",
        "    for i in range(3):\n",
        "        out[:,i] = signal.resample(data[:,i], N)\n",
        "    return out\n",
        "\n",
        "def make_windows(acc_data, win_size=300, overlap=0.5):\n",
        "    step = int(win_size * (1-overlap))\n",
        "    W = []\n",
        "    for i in range(0, len(acc_data)-win_size+1, step):\n",
        "        W.append(acc_data[i:i+win_size])\n",
        "    return np.stack(W)"
      ],
      "metadata": {
        "id": "hq6fHiak8ZKv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_acc(db_path)\n",
        "acc = df[['x_value','y_value','z_value']].values\n",
        "ts  = df['timestamp']\n",
        "acc30 = resample_30hz(acc, ts)\n",
        "wins = make_windows(acc30, win_size=300, overlap=0.5)"
      ],
      "metadata": {
        "id": "2YPWWwwf84El"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Windows generated:\", wins.shape)  # (n_windows, 300, 3)\n",
        "\n",
        "wins = np.transpose(wins, (0,2,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_U5WFEU85zR",
        "outputId": "969210de-9e8c-409a-f96d-1287661f4244"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windows generated: (199, 300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "repo = 'OxWearables/ssl-wearables'\n",
        "num_classes = 4  # Capture-24 ha 4 classi\n",
        "model = torch.hub.load(repo, 'harnet10', class_num=num_classes, pretrained=True, trust_repo=True)\n",
        "\n",
        "feat_dim = model.feature_extractor(torch.randn(1,3,300,device=device)).shape[1]\n",
        "for p in model.feature_extractor.parameters(): p.requires_grad=False\n",
        "model.classifier = nn.Linear(feat_dim, num_classes)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNEmyu-69CYU",
        "outputId": "fe8821f6-f56c-45ef-a5fb-7fe447f53abb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 Weights loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resnet(\n",
              "  (feature_extractor): Sequential(\n",
              "    (layer1): Sequential(\n",
              "      (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer5): Sequential(\n",
              "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Downsample()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = '/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/finetuned_harnet10.pth'\n",
        "\n",
        "sd = torch.load(ckpt, map_location=device)\n",
        "model.load_state_dict(sd, strict=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugW2JHD39bg0",
        "outputId": "aab04221-e777-4d6d-e0ba-6aa10c21ac31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resnet(\n",
              "  (feature_extractor): Sequential(\n",
              "    (layer1): Sequential(\n",
              "      (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Downsample()\n",
              "    )\n",
              "    (layer5): Sequential(\n",
              "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Downsample()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.from_numpy(wins).float().to(device)\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(batch), 256):\n",
        "        out = model(batch[i:i+256])\n",
        "        preds.append(out.argmax(1).cpu().numpy())\n",
        "preds = np.concatenate(preds, axis=0)\n",
        "print(\"Predizioni effettuate:\", preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gji4SxnA9uWG",
        "outputId": "e9ef1c23-cc90-4cd7-8d88-c9968cbad42d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predizioni effettuate: (199,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step = int(300 * 0.5)\n",
        "start_time = pd.to_datetime(ts.iloc[0])\n",
        "resampled_times = pd.date_range(start=start_time, periods=len(acc30), freq='33.333ms')\n",
        "start_indices = np.arange(0, len(acc30)-300+1, step)\n",
        "df_labels = pd.DataFrame({\n",
        "    'start_time': resampled_times[start_indices],\n",
        "    'end_time': resampled_times[start_indices + 300],\n",
        "    'predicted_class': preds\n",
        "})\n",
        "\n",
        "df_labels['predicted_class_str'] = df_labels['predicted_class'].map(idx2class)"
      ],
      "metadata": {
        "id": "wtMR6BBW-YNy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_csv = '/content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/health_data_labels.csv'\n",
        "df_labels.to_csv(out_csv, index=False)\n",
        "print(\"Labels salvate in\", out_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgS8SdUa-afc",
        "outputId": "fd93661b-fd49-4513-d3ce-e9382ad6103d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels salvate in /content/drive/MyDrive/Borsa di ricerca/Post First Paper/Paper Activity recognition/Code Research/HAR/health_data_labels.csv\n"
          ]
        }
      ]
    }
  ]
}